{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvWIItAe-0fN"
      },
      "source": [
        "[![Open In Colab](https://raw.githubusercontent.com/crunchdao/competitions/refs/heads/master/documentation/badge/open-in-colab.svg)](https://colab.research.google.com/github/crunchdao/quickstarters/blob/master/competitions/structural-break/quickstarters/baseline/baseline.ipynb)\n",
        "[![Open In Kaggle](https://raw.githubusercontent.com/crunchdao/competitions/refs/heads/master/documentation/badge/open-in-kaggle.svg)](https://www.kaggle.com/code/crunchdao/structural-break-baseline)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install hmmlearn"
      ],
      "metadata": {
        "id": "qz4d4-WK76aN",
        "outputId": "3b0eb255-b3dc-4456-ccae-952a0cea851e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.12/dist-packages (from hmmlearn) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.12/dist-packages (from hmmlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.12/dist-packages (from hmmlearn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.6.0)\n",
            "Downloading hmmlearn-0.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DUeixiC_IJM",
        "outputId": "1d3a39ad-52fa-46cd-97ab-122363939780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "crunch-cli, version 7.5.0\n",
            "main.py: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/submissions/25492/main.py (17703 bytes)\n",
            "notebook.ipynb: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/submissions/25492/notebook.ipynb (51157 bytes)\n",
            "requirements.txt: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/submissions/25492/requirements.original.txt (194 bytes)\n",
            "resources/xgb_model1.joblib: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/models/26814/xgb_model1.joblib (332638 bytes)\n",
            "data/X_train.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/X_train.parquet (204327238 bytes)\n",
            "data/X_test.reduced.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/X_test.reduced.parquet (2380918 bytes)\n",
            "data/y_train.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/y_train.parquet (61003 bytes)\n",
            "data/y_test.reduced.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/y_test.reduced.parquet (2655 bytes)\n",
            "                                \n",
            "---\n",
            "Success! Your environment has been correctly setup.\n",
            "Next recommended actions:\n",
            "1. Load the Crunch Toolings: `crunch = crunch.load_notebook()`\n",
            "2. Execute the cells with your code\n",
            "3. Run a test: `crunch.test()`\n",
            "4. Download and submit your code to the platform!\n"
          ]
        }
      ],
      "source": [
        "%pip install crunch-cli --upgrade --quiet --progress-bar off\n",
        "!crunch setup-notebook structural-break BMYVWHdIAaaPrmCMo7VtBD4Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-18T09:52:21.302334Z",
          "start_time": "2024-11-18T09:52:18.268241Z"
        },
        "id": "MKqz-6Zw-0fR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import typing\n",
        "\n",
        "# Import your dependencies\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import sklearn.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjD_WSAS-0fR",
        "outputId": "372bca07-43b1-40c5-f267-b07982e15db7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded inline runner with module: <module '__main__'>\n",
            "\n",
            "cli version: 7.5.0\n",
            "available ram: 12.67 gb\n",
            "available cpu: 2 core\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "import crunch\n",
        "\n",
        "# Load the Crunch Toolings\n",
        "crunch = crunch.load_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKHXgvjN-0fS",
        "outputId": "6e61d6d5-a32a-4570-cf28-e00856df4139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/X_train.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/X_train.parquet (204327238 bytes)\n",
            "data/X_train.parquet: already exists, file length match\n",
            "data/X_test.reduced.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/X_test.reduced.parquet (2380918 bytes)\n",
            "data/X_test.reduced.parquet: already exists, file length match\n",
            "data/y_train.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/y_train.parquet (61003 bytes)\n",
            "data/y_train.parquet: already exists, file length match\n",
            "data/y_test.reduced.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/y_test.reduced.parquet (2655 bytes)\n",
            "data/y_test.reduced.parquet: already exists, file length match\n"
          ]
        }
      ],
      "source": [
        "# Load the data simply\n",
        "X_train, y_train, X_test = crunch.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-18T10:04:00.459399Z",
          "start_time": "2024-11-18T10:04:00.455716Z"
        },
        "id": "xQwWDC6M-0fT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import typing\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from hmmlearn import hmm\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings from hmmlearn for cleaner output\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "\n",
        "def train(\n",
        "    X_train: pd.DataFrame,\n",
        "    y_train: pd.Series,\n",
        "    model_directory_path: str,\n",
        "):\n",
        "    \"\"\"\n",
        "    Trains the model. For this HMM approach, \"training\" involves setting and\n",
        "    saving the model's hyperparameters. A more advanced version could use\n",
        "    X_train and y_train to find the optimal number of hidden states.\n",
        "    \"\"\"\n",
        "    # We hypothesize that a break involves a shift between two primary regimes.\n",
        "    # Therefore, we fix the number of hidden states to 2.\n",
        "    config = {\n",
        "        'n_states': 2,\n",
        "        'n_iter': 100,\n",
        "        'covariance_type': 'diag',\n",
        "        'random_state': 42  # Add a fixed seed for determinism\n",
        "    }\n",
        "\n",
        "    # Save the configuration object to be loaded during inference.\n",
        "    joblib.dump(config, os.path.join(model_directory_path, 'model.joblib'))\n",
        "    print(\"Model configuration saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-18T10:03:59.120294Z",
          "start_time": "2024-11-18T10:03:59.114830Z"
        },
        "id": "r1b7hRkl-0fU"
      },
      "outputs": [],
      "source": [
        "def infer(\n",
        "    X_test: typing.Iterable[pd.DataFrame],\n",
        "    model_directory_path: str,\n",
        ") -> typing.Generator[float, None, None]:\n",
        "    \"\"\"\n",
        "    Makes predictions on the test data using the HMM-based structural break detection.\n",
        "    \"\"\"\n",
        "    # Load the model configuration saved during the training phase.\n",
        "    config = joblib.load(os.path.join(model_directory_path, 'model.joblib'))\n",
        "    n_states = config['n_states']\n",
        "    n_iter = config['n_iter']\n",
        "\n",
        "    yield  # Mark as ready to receive data\n",
        "\n",
        "    # X_test can only be iterated once.\n",
        "    for dataset in X_test:\n",
        "        try:\n",
        "            # 1. Pre-process the data: Use log returns to stabilize variance.\n",
        "            # Using price directly can be problematic if it's not stationary.\n",
        "            log_returns = np.log(dataset['value']).diff().dropna()\n",
        "\n",
        "            # Align the period labels with the log returns\n",
        "            periods = dataset['period'].iloc[1:]\n",
        "\n",
        "            series_pre = log_returns[periods == 0].values.reshape(-1, 1)\n",
        "            series_post = log_returns[periods == 1].values.reshape(-1, 1)\n",
        "\n",
        "            # 2. Check for sufficient data in each period to fit a model.\n",
        "            if len(series_pre) < n_states * 2 or len(series_post) < n_states * 2:\n",
        "                yield 0.5  # Not enough data, yield a neutral score\n",
        "                continue\n",
        "\n",
        "            # 3. Fit HMMs to each period.\n",
        "            model_pre = hmm.GaussianHMM(n_components=n_states, covariance_type=config['covariance_type'], n_iter=n_iter)\n",
        "            model_pre.fit(series_pre)\n",
        "\n",
        "            model_post = hmm.GaussianHMM(n_components=n_states, covariance_type=config['covariance_type'], n_iter=n_iter)\n",
        "            model_post.fit(series_post)\n",
        "\n",
        "            # 4. Calculate log-likelihoods, normalized by series length.\n",
        "            # This measures how well each model explains its own data vs. the other's data.\n",
        "            len_pre, len_post = len(series_pre), len(series_post)\n",
        "            ll_pre_pre = model_pre.score(series_pre) / len_pre\n",
        "            ll_post_post = model_post.score(series_post) / len_post\n",
        "            ll_pre_post = model_post.score(series_pre) / len_pre\n",
        "            ll_post_pre = model_pre.score(series_post) / len_post\n",
        "\n",
        "            # 5. Compute the symmetric log-likelihood ratio as the break score.\n",
        "            # A large positive value indicates the models are very different.\n",
        "            raw_score = (ll_pre_pre + ll_post_post) - (ll_pre_post + ll_post_pre)\n",
        "\n",
        "            # 6. Normalize the score to a probability [0, 1] using the sigmoid function.\n",
        "            prediction = 1 / (1 + np.exp(-raw_score))\n",
        "\n",
        "            yield prediction\n",
        "\n",
        "        except Exception as e:\n",
        "            # If any error occurs (e.g., HMM fails to converge), yield a neutral score.\n",
        "            print(f\"An error occurred for a dataset: {e}. Yielding neutral score.\")\n",
        "            yield 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDZeP-4--0fU",
        "outputId": "8247468c-9e9a-47cd-d374-a8f943a0ad87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "08:42:06 no forbidden library found\n",
            "08:42:06 \n",
            "08:42:06 started\n",
            "08:42:06 running local test\n",
            "08:42:06 internet access isn't restricted, no check will be done\n",
            "08:42:06 \n",
            "08:42:07 starting unstructured loop...\n",
            "08:42:07 executing - command=train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/X_train.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/X_train.parquet (204327238 bytes)\n",
            "data/X_train.parquet: already exists, file length match\n",
            "data/X_test.reduced.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/X_test.reduced.parquet (2380918 bytes)\n",
            "data/X_test.reduced.parquet: already exists, file length match\n",
            "data/y_train.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/y_train.parquet (61003 bytes)\n",
            "data/y_train.parquet: already exists, file length match\n",
            "data/y_test.reduced.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/y_test.reduced.parquet (2655 bytes)\n",
            "data/y_test.reduced.parquet: already exists, file length match\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "08:42:09 executing - command=infer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model configuration saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "08:42:18 checking determinism by executing the inference again with 30% of the data (tolerance: 1e-08)\n",
            "08:42:18 executing - command=infer\n",
            "08:42:20 determinism check: failed\n",
            "08:42:20 save prediction - path=data/prediction.parquet\n",
            "08:42:20 ended\n",
            "08:42:20 duration - time=00:00:13\n",
            "08:42:20 memory - before=\"905.8 MB\" after=\"939.49 MB\" consumed=\"33.69 MB\"\n"
          ]
        }
      ],
      "source": [
        "crunch.test(\n",
        "    # Uncomment to disable the train\n",
        "    # force_first_train=False,\n",
        "\n",
        "    # Uncomment to disable the determinism check\n",
        "    # no_determinism_check=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV_5CKs--0fU"
      },
      "source": [
        "## Results\n",
        "\n",
        "Once the local tester is done, you can preview the result stored in `data/prediction.parquet`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly5q68sA-0fU"
      },
      "outputs": [],
      "source": [
        "prediction = pd.read_parquet(\"data/prediction.parquet\")\n",
        "prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oP-NLGh-0fU"
      },
      "source": [
        "### Local scoring\n",
        "\n",
        "You can call the function that the system uses to estimate your score locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyCrjpzv-0fU"
      },
      "outputs": [],
      "source": [
        "# Load the targets\n",
        "target = pd.read_parquet(\"data/y_test.reduced.parquet\")[\"structural_breakpoint\"]\n",
        "\n",
        "# Call the scoring function\n",
        "sklearn.metrics.roc_auc_score(\n",
        "    target,\n",
        "    prediction,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AE1i3pR-0fV"
      },
      "source": [
        "# Submit your Notebook\n",
        "\n",
        "To submit your work, you must:\n",
        "1. Download your Notebook from Colab\n",
        "2. Upload it to the platform\n",
        "3. Create a run to validate it\n",
        "\n",
        "### >> https://hub.crunchdao.com/competitions/structural-break/submit/notebook\n",
        "\n",
        "![Download and Submit Notebook](https://raw.githubusercontent.com/crunchdao/competitions/refs/heads/master/documentation/animations/download-and-submit-notebook.gif)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}